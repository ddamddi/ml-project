{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([#transforms.Resize((1,10000)),\n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = 'horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# print(trainset)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = 'horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False, num_workers=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label shape : (1, 1027)\n",
      "train_data shape  : (10000, 1027)\n",
      "val_label shape   : (1, 256)\n",
      "val_label shape   : (10000, 256)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.zeros((10000, 0))\n",
    "train_label = np.zeros((0,1))\n",
    "val_data = np.zeros((10000,0))\n",
    "val_label = np.zeros((0,1))\n",
    "\n",
    "# load training images of the batch size for every iteration\n",
    "for i, data in enumerate(trainloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    train_data = np.hstack((train_data, np.reshape(inputs, (10000,1))))\n",
    "    \n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    train_label = np.append(train_label, labels)\n",
    "\n",
    "train_label = train_label.reshape(1,1027)\n",
    "\n",
    "\n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    val_data = np.hstack((val_data, np.reshape(inputs, (10000,1))))\n",
    "\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    val_label = np.append(val_label, labels)\n",
    "\n",
    "val_label = val_label.reshape(1,256)\n",
    "\n",
    "\n",
    "print(\"train_label shape : \" + str(train_label.shape))\n",
    "print(\"train_data shape  : \" + str(train_data.shape))\n",
    "print(\"val_label shape   : \" + str(val_label.shape))\n",
    "print(\"val_label shape   : \" +str(val_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.002\n",
    "NUM_EPOCH = 5000\n",
    "NUM_TRAIN_DATA = 1027\n",
    "NUM_VAL_DATA = 256\n",
    "\n",
    "w = np.zeros((10000, 1))\n",
    "b = 0\n",
    "\n",
    "train_loss = np.zeros((2,NUM_EPOCH))\n",
    "train_accuracy = np.zeros((2,NUM_EPOCH))\n",
    "val_loss = np.zeros((2,NUM_EPOCH))\n",
    "val_accuracy = np.zeros((2,NUM_EPOCH))\n",
    "elapsed_time = np.zeros((2, NUM_EPOCH))\n",
    "\n",
    "for i in range(NUM_EPOCH):\n",
    "    \n",
    "    J = 0\n",
    "    dw = np.zeros((10000, 1))\n",
    "    dz = 0\n",
    "    \n",
    "    # COMPUTATION OF THE GRADIENT AND UPDATE OF MODEL PARAMETERS\n",
    "    start_time = time.time()\n",
    "    z = np.dot(w.T, train_data) + b\n",
    "    A = 1/(1 + np.exp(-z))\n",
    "    \n",
    "    dz = A - train_label\n",
    "    dw = np.dot(dz, train_data.T) / NUM_TRAIN_DATA\n",
    "    db = np.sum(dz) / NUM_TRAIN_DATA\n",
    "    \n",
    "    w = w - LEARNING_RATE * dw.reshape(10000,1)\n",
    "    b = b - LEARNING_RATE * db \n",
    "    \n",
    "    elapsed_time[0][i] = i+1\n",
    "    elapsed_time[1][i] = time.time() - start_time\n",
    "    \n",
    "    # FOR CALCULATING TRAIN LOSS\n",
    "    J = (np.dot(train_label, (np.log(A)).T) + np.dot(1-train_label, (np.log(1-A)).T))\n",
    "    J = -np.sum(J)/NUM_TRAIN_DATA\n",
    "    train_loss[0][i] = i+1\n",
    "    train_loss[1][i] = J\n",
    "    \n",
    "    # FOR CALCULATING TRAIN ACCURACY\n",
    "    for x in range(NUM_TRAIN_DATA):\n",
    "        if A[0][x] >= 0.5:\n",
    "            A[0][x] = 1\n",
    "        else:\n",
    "            A[0][x] = 0\n",
    "    \n",
    "    correct = 0\n",
    "    for x in range(NUM_TRAIN_DATA):\n",
    "        if A[0][x] == train_label[0][x]:\n",
    "            correct += 1\n",
    "        \n",
    "    train_accuracy[0][i] = i+1\n",
    "    train_accuracy[1][i] = correct/NUM_TRAIN_DATA\n",
    "    \n",
    "    # FOR CALCULATING TEST LOSS\n",
    "    z = np.dot(w.T, val_data) + b\n",
    "    A = 1/(1 + np.exp(-z))\n",
    "    \n",
    "    J = (np.dot(val_label, (np.log(A)).T) + np.dot(1-val_label, (np.log(1-A)).T))\n",
    "    J = -np.sum(J)/NUM_VAL_DATA\n",
    "    val_loss[0][i] = i+1\n",
    "    val_loss[1][i] = J\n",
    "    \n",
    "    # FOR CALCULATING TEST ACCURACY\n",
    "    for x in range(NUM_VAL_DATA):\n",
    "        if A[0][x] >= 0.5:\n",
    "            A[0][x] = 1\n",
    "        else:\n",
    "            A[0][x] = 0\n",
    "    \n",
    "    correct = 0\n",
    "    for x in range(NUM_VAL_DATA):\n",
    "        if A[0][x] == val_label[0][x]:\n",
    "            correct += 1\n",
    "        \n",
    "    val_accuracy[0][i] = i+1\n",
    "    val_accuracy[1][i] = correct/NUM_VAL_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ELAPSED TIME AT EVERY TRAINING ITERATION \n",
    "plt.figure(figsize=(20,8))\n",
    "plt.title(\"Elapsed time at every train iterations\", fontsize=\"15\")\n",
    "plt.xlabel(\"iteration\", fontsize='12')\n",
    "plt.ylabel(\"Elapsed time (sec)\", fontsize='12' )\n",
    "plt.plot(elapsed_time[0], elapsed_time[1], '-b', label='Elapsed time')\n",
    "plt.legend(fontsize='12')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLOT TRAIN AND VALIDATION LOSS AT EVERY ITERATION\n",
    "fig, ax2 = plt.subplots(1,2,figsize=(20,6))\n",
    "ax2[0].set_title(\"Loss Value\")\n",
    "ax2[0].set_ylabel(\"Loss\", fontsize=\"12\")\n",
    "ax2[0].set_xlabel(\"iteration\", fontsize=\"12\")\n",
    "ax2[0].plot(train_loss[0], train_loss[1],'-r', label='Train Loss')\n",
    "ax2[0].plot(val_loss[0], val_loss[1], '-b', label='Validation Loss')\n",
    "ax2[0].legend(fontsize=\"12\")\n",
    "\n",
    "# PLOT TRAIN AND VALIDATION ACCURACY AT EVERY ITERATION\n",
    "ax2[1].set_title(\"Accuracy\")\n",
    "ax2[1].set_ylabel(\"Accuracy\", fontsize=\"12\")\n",
    "ax2[1].set_xlabel(\"iteration\", fontsize=\"12\")\n",
    "ax2[1].plot(train_accuracy[0], train_accuracy[1], '-y', label='Train Accuracy')\n",
    "ax2[1].plot(val_accuracy[0], val_accuracy[1], '-g', label='Validation Accuracy')\n",
    "ax2[1].legend(fontsize=\"12\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND FINAL ACCURACY AND LOSS OF DATASETS\n",
    "temp = val_loss[1][0]\n",
    "index = val_loss[0][0]\n",
    "for x in range(NUM_EPOCH):\n",
    "    if temp > val_loss[1][x]:\n",
    "        temp = val_loss[1][x]\n",
    "        index = val_loss[0][x]\n",
    "\n",
    "index = int(index)\n",
    "\n",
    "print(\"Fit at \" + str(index) +\"th iteration\")\n",
    "print(\"Train_Loss     : \" + str(train_loss[1][index]))\n",
    "print(\"Train_Accuracy : \" + str(train_accuracy[1][index]))\n",
    "print(\"Val_Loss       : \" + str(val_loss[1][index]))\n",
    "print(\"Val_Accuracy   : \" + str(val_accuracy[1][index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Final accuracy and loss with training and validation datasets\n",
    "\n",
    "Dataset | Loss | Accuracy\n",
    ":--- | :---: | :---:\n",
    "Training | 0.391 | 85.1%\n",
    "Validation | 0.305  | 87.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
