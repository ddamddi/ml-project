{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([#transforms.Resize((1,10000)),\n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '..\\\\Assignment#2\\\\horse-or-human\\\\train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# print(trainset)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = '..\\\\Assignment#2\\\\horse-or-human\\\\validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False, num_workers=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label shape : (1, 1027)\n",
      "train_data shape  : (10000, 1027)\n",
      "val_label shape   : (1, 256)\n",
      "val_label shape   : (10000, 256)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.zeros((10000, 0))\n",
    "train_label = np.zeros((0,1))\n",
    "val_data = np.zeros((10000,0))\n",
    "val_label = np.zeros((0,1))\n",
    "\n",
    "# load training images of the batch size for every iteration\n",
    "for i, data in enumerate(trainloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    train_data = np.hstack((train_data, np.reshape(inputs, (10000,1))))\n",
    "    \n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    train_label = np.append(train_label, labels)\n",
    "\n",
    "train_label = train_label.reshape(1,1027)\n",
    "\n",
    "\n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    val_data = np.hstack((val_data, np.reshape(inputs, (10000,1))))\n",
    "\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    val_label = np.append(val_label, labels)\n",
    "\n",
    "val_label = val_label.reshape(1,256)\n",
    "\n",
    "\n",
    "print(\"train_label shape : \" + str(train_label.shape))\n",
    "print(\"train_data shape  : \" + str(train_data.shape))\n",
    "print(\"val_label shape   : \" + str(val_label.shape))\n",
    "print(\"val_label shape   : \" + str(val_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-36d913dcf849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mIMAGE_VECTOR_LEN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mw_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mw_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mw_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randn\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.standard_normal\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES, EPOCH, LEARNING RATE\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCH = 10000\n",
    "NUM_TRAIN_DATA = train_data.shape[1]\n",
    "NUM_VAL_DATA = val_data.shape[1]\n",
    "IMAGE_VECTOR_LEN = train_data.shape[0]\n",
    "\n",
    "w_1 = np.random.randn(4,10000) * 0.01\n",
    "w_2 = np.random.randn(3, 4) * 0.01\n",
    "w_3 = np.random.randn(1, 3) * 0.01\n",
    "\n",
    "b_1 = 0\n",
    "b_2 = 0\n",
    "b_3 = 0\n",
    "\n",
    "train_loss = np.zeros((2,NUM_EPOCH))\n",
    "train_accuracy = np.zeros((2,NUM_EPOCH))\n",
    "val_loss = np.zeros((2,NUM_EPOCH))\n",
    "val_accuracy = np.zeros((2,NUM_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_EPOCH):  \n",
    "    J = 0   \n",
    "    dw_1 = np.zeros((4, 10000))\n",
    "    dw_2 = np.zeros((3, 4))\n",
    "    dw_3 = np.zeros((1, 3))\n",
    "    \n",
    "    db_1 = 0\n",
    "    db_2 = 0\n",
    "    db_3 = 0\n",
    "    \n",
    "    dz_1 = 0\n",
    "    dz_2 = 0\n",
    "    dz_3 = 0\n",
    "    \n",
    "    # COMPUTATION OF THE GRADIENT AND UPDATE OF MODEL PARAMETERS\n",
    "    z_1 = np.dot(w_1, train_data) + b_1\n",
    "    A_1 = sigmoid(z_1)\n",
    "#     print(str(A_1.shape))\n",
    "    \n",
    "    z_2 = np.dot(w_2, A_1) + b_2\n",
    "    A_2 = sigmoid(z_2)\n",
    "#     print(str(A_2.shape))\n",
    "    \n",
    "    z_3 = np.dot(w_3, A_2) + b_3\n",
    "    A_3 = sigmoid(z_3)\n",
    "#     print(str(A_3.shape))\n",
    "    \n",
    "    # COMPUTAION OF DERIVATIVES\n",
    "    dz_3 = A_3 - train_label\n",
    "#     print(str(dz_3.shape))\n",
    "#     print(str(A_2.shape))\n",
    "    dw_3 = np.dot(dz_3, A_2.T) / NUM_TRAIN_DATA\n",
    "#     print(str(dw_3.shape))\n",
    "    db_3 = np.sum(dz_3, axis=1, keepdims=True) / NUM_TRAIN_DATA\n",
    "#     print(str(db_3.shape))\n",
    "    \n",
    "    dz_2 = np.dot(w_3.T, dz_3) *  z_2 * (1- z_2)\n",
    "#     print(str(w_3.shape))\n",
    "#     print(str(dz_3.shape))\n",
    "#     print(str(z_2.shape))\n",
    "#     print(str(dz_2.shape))\n",
    "    dw_2 = np.dot(dz_2, A_1.T) / NUM_TRAIN_DATA\n",
    "#     print(str(dw_2.shape))\n",
    "    db_2 = np.sum(dz_2, axis=1, keepdims=True) / NUM_TRAIN_DATA\n",
    "#     print(str(db_2.shape))\n",
    "    \n",
    "    dz_1 = np.dot(w_2.T, dz_2) * z_1 * (1- z_1)\n",
    "#     print(str(w_2.shape))\n",
    "#     print(str(dz_2.shape))\n",
    "#     print(str(z_1.shape))\n",
    "#     print(str(dz_1.shape))\n",
    "    dw_1 = np.dot(dz_1, train_data.T) / NUM_TRAIN_DATA\n",
    "    db_1 = np.sum(dz_1, axis=1, keepdims=True) / NUM_TRAIN_DATA\n",
    "    \n",
    "    # UPDATE PARAMETERS\n",
    "    w_1 = w_1 - LEARNING_RATE * dw_1\n",
    "    w_2 = w_2 - LEARNING_RATE * dw_2\n",
    "    w_3 = w_3 - LEARNING_RATE * dw_3\n",
    "    \n",
    "    b_1 = b_1 - LEARNING_RATE * db_1\n",
    "    b_2 = b_2 - LEARNING_RATE * db_2\n",
    "    b_3 = b_3 - LEARNING_RATE * db_3\n",
    "    \n",
    "    \n",
    "    # FOR CALCULATING TRAIN LOSS\n",
    "    J = (np.dot(train_label, (np.log(A_3)).T) + np.dot(1-train_label, (np.log(1-A_3)).T))\n",
    "    J = -np.sum(J) / NUM_TRAIN_DATA\n",
    "    train_loss[0][i] = i+1\n",
    "    train_loss[1][i] = J\n",
    "    \n",
    "    # FOR CALCULATING TRAIN ACCURACY\n",
    "#     for x in range(NUM_TRAIN_DATA):\n",
    "#         if A_3[0][x] >= 0.5:\n",
    "#             A_3[0][x] = 1\n",
    "#         else:\n",
    "#             A_3[0][x] = 0\n",
    "    \n",
    "#     correct = 0\n",
    "#     for x in range(NUM_TRAIN_DATA):\n",
    "#         if A_3[0][x] == train_label[0][x]:\n",
    "#             correct += 1\n",
    "        \n",
    "#     train_accuracy[0][i] = i+1\n",
    "#     train_accuracy[1][i] = correct/NUM_TRAIN_DATA\n",
    "    \n",
    "    # FOR CALCULATING VALIDATION LOSS   \n",
    "    z_1 = np.dot(w_1, val_data) + b_1\n",
    "    A_1 = sigmoid(z_1)\n",
    "    \n",
    "    z_2 = np.dot(w_2, A_1) + b_2\n",
    "    A_2 = sigmoid(z_2)\n",
    "    \n",
    "    z_3 = np.dot(w_3, A_2) + b_3\n",
    "    A_3 = sigmoid(z_3)\n",
    "    \n",
    "    J = (np.dot(val_label, (np.log(A_3)).T) + np.dot(1-val_label, (np.log(1-A_3)).T))\n",
    "    J = -np.sum(J)/NUM_VAL_DATA\n",
    "    val_loss[0][i] = i+1\n",
    "    val_loss[1][i] = J\n",
    "    \n",
    "    # FOR CALCULATING VALIDATION ACCURACY\n",
    "#     for x in range(NUM_VAL_DATA):\n",
    "#         if A_3[0][x] >= 0.5:\n",
    "#             A_3[0][x] = 1\n",
    "#         else:\n",
    "#             A_3[0][x] = 0\n",
    "    \n",
    "#     correct = 0\n",
    "#     for x in range(NUM_VAL_DATA):\n",
    "#         if A_3[0][x] == val_label[0][x]:\n",
    "#             correct += 1\n",
    "        \n",
    "#     val_accuracy[0][i] = i+1\n",
    "#     val_accuracy[1][i] = correct/NUM_VAL_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN AND VALIDATION LOSS AT EVERY ITERATION\n",
    "fig, ax2 = plt.subplots(1,2,figsize=(20,6))\n",
    "ax2[0].set_title(\"Loss Value\")\n",
    "ax2[0].set_ylabel(\"Loss\", fontsize=\"12\")\n",
    "ax2[0].set_xlabel(\"iteration\", fontsize=\"12\")\n",
    "ax2[0].plot(train_loss[0], train_loss[1],'-r', label='Train Loss')\n",
    "ax2[0].plot(val_loss[0], val_loss[1], '-b', label='Validation Loss')\n",
    "ax2[0].legend(fontsize=\"12\")\n",
    "\n",
    "# PLOT TRAIN AND VALIDATION ACCURACY AT EVERY ITERATION\n",
    "ax2[1].set_title(\"Accuracy\")\n",
    "ax2[1].set_ylabel(\"Accuracy\", fontsize=\"12\")\n",
    "ax2[1].set_xlabel(\"iteration\", fontsize=\"12\")\n",
    "ax2[1].plot(train_accuracy[0], train_accuracy[1], '-y', label='Train Accuracy')\n",
    "ax2[1].plot(val_accuracy[0], val_accuracy[1], '-g', label='Validation Accuracy')\n",
    "ax2[1].legend(fontsize=\"12\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
