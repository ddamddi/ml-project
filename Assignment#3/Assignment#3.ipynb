{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([#transforms.Resize((1,10000)),\n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '..\\\\Assignment#2\\\\horse-or-human\\\\train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# print(trainset)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = '..\\\\Assignment#2\\\\horse-or-human\\\\validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False, num_workers=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label shape : (1, 1027)\n",
      "train_data shape  : (10000, 1027)\n",
      "val_label shape   : (1, 256)\n",
      "val_label shape   : (10000, 256)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.zeros((10000, 0))\n",
    "train_label = np.zeros((0,1))\n",
    "val_data = np.zeros((10000,0))\n",
    "val_label = np.zeros((0,1))\n",
    "\n",
    "# load training images of the batch size for every iteration\n",
    "for i, data in enumerate(trainloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    train_data = np.hstack((train_data, np.reshape(inputs, (10000,1))))\n",
    "    \n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    train_label = np.append(train_label, labels)\n",
    "\n",
    "train_label = train_label.reshape(1,1027)\n",
    "\n",
    "\n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    val_data = np.hstack((val_data, np.reshape(inputs, (10000,1))))\n",
    "\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    val_label = np.append(val_label, labels)\n",
    "\n",
    "val_label = val_label.reshape(1,256)\n",
    "\n",
    "\n",
    "print(\"train_label shape : \" + str(train_label.shape))\n",
    "print(\"train_data shape  : \" + str(train_data.shape))\n",
    "print(\"val_label shape   : \" + str(val_label.shape))\n",
    "print(\"val_label shape   : \" + str(val_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE VARIABLES, EPOCH, LEARNING RATE\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_EPOCH = 20000\n",
    "NUM_HIDDEN_LAYER_1 = 3\n",
    "NUM_HIDDEN_LAYER_2 = 2\n",
    "\n",
    "NUM_TRAIN_DATA = train_data.shape[1]\n",
    "NUM_VAL_DATA = val_data.shape[1]\n",
    "IMAGE_VECTOR_LEN = train_data.shape[0]\n",
    "\n",
    "w_1 = np.random.randn(NUM_HIDDEN_LAYER_1,10000)\n",
    "w_2 = np.random.randn(NUM_HIDDEN_LAYER_2, NUM_HIDDEN_LAYER_1)\n",
    "w_3 = np.random.randn(1, NUM_HIDDEN_LAYER_2)\n",
    "\n",
    "b_1 = 0\n",
    "b_2 = 0\n",
    "b_3 = 0\n",
    "\n",
    "train_loss = np.zeros((2,NUM_EPOCH))\n",
    "train_accuracy = np.zeros((2,NUM_EPOCH))\n",
    "val_loss = np.zeros((2,NUM_EPOCH))\n",
    "val_accuracy = np.zeros((2,NUM_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 Done\n",
      "Epoch 2000 Done\n",
      "Epoch 3000 Done\n",
      "Epoch 4000 Done\n",
      "Epoch 5000 Done\n",
      "Epoch 6000 Done\n",
      "Epoch 7000 Done\n",
      "Epoch 8000 Done\n",
      "Epoch 9000 Done\n",
      "Epoch 10000 Done\n",
      "Epoch 11000 Done\n",
      "Epoch 12000 Done\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCH):  \n",
    "    J = 0   \n",
    "    dw_1 = np.zeros((NUM_HIDDEN_LAYER_1, 10000))\n",
    "    dw_2 = np.zeros((NUM_HIDDEN_LAYER_2, NUM_HIDDEN_LAYER_1))\n",
    "    dw_3 = np.zeros((1, NUM_HIDDEN_LAYER_2))\n",
    "    \n",
    "    db_1 = 0\n",
    "    db_2 = 0\n",
    "    db_3 = 0\n",
    "    \n",
    "    dz_1 = 0\n",
    "    dz_2 = 0\n",
    "    dz_3 = 0\n",
    "    \n",
    "    # COMPUTATION OF THE GRADIENT AND UPDATE OF MODEL PARAMETERS\n",
    "    z_1 = np.dot(w_1, train_data) + b_1\n",
    "    A_1 = sigmoid(z_1)\n",
    "    \n",
    "    z_2 = np.dot(w_2, A_1) + b_2\n",
    "    A_2 = sigmoid(z_2)\n",
    "\n",
    "    z_3 = np.dot(w_3, A_2) + b_3\n",
    "    A_3 = sigmoid(z_3)\n",
    "\n",
    "    # COMPUTAION OF DERIVATIVES\n",
    "    dz_3 = A_3 - train_label\n",
    "    dw_3 = np.dot(dz_3, A_2.T) / NUM_TRAIN_DATA\n",
    "    db_3 = np.sum(dz_3, axis=1, keepdims=True) / NUM_TRAIN_DATA\n",
    "\n",
    "    dz_2 = np.dot(w_3.T, dz_3) *  A_2 * (1- A_2)\n",
    "    dw_2 = np.dot(dz_2, A_1.T) / NUM_TRAIN_DATA\n",
    "    db_2 = np.sum(dz_2, axis=1, keepdims=True) / NUM_TRAIN_DATA\n",
    "    \n",
    "    dz_1 = np.dot(w_2.T, dz_2) * A_1 * (1- A_1)\n",
    "    dw_1 = np.dot(dz_1, train_data.T) / NUM_TRAIN_DATA\n",
    "    db_1 = np.sum(dz_1, axis=1, keepdims=True) / NUM_TRAIN_DATA\n",
    "    \n",
    "    # UPDATE PARAMETERS\n",
    "    w_1 = w_1 - LEARNING_RATE * dw_1\n",
    "    w_2 = w_2 - LEARNING_RATE * dw_2\n",
    "    w_3 = w_3 - LEARNING_RATE * dw_3\n",
    "    \n",
    "    b_1 = b_1 - LEARNING_RATE * db_1\n",
    "    b_2 = b_2 - LEARNING_RATE * db_2\n",
    "    b_3 = b_3 - LEARNING_RATE * db_3\n",
    "    \n",
    "    \n",
    "    # FOR CALCULATING TRAIN LOSS\n",
    "    J = (np.dot(train_label, (np.log(A_3)).T) + np.dot(1-train_label, (np.log(1-A_3)).T))\n",
    "    J = -np.sum(J) / NUM_TRAIN_DATA\n",
    "    train_loss[0][i] = i+1\n",
    "    train_loss[1][i] = J\n",
    "    \n",
    "    # FOR CALCULATING TRAIN ACCURACY\n",
    "    for x in range(NUM_TRAIN_DATA):\n",
    "        if A_3[0][x] >= 0.5:\n",
    "            A_3[0][x] = 1\n",
    "        else:\n",
    "            A_3[0][x] = 0\n",
    "    \n",
    "    correct = 0\n",
    "    for x in range(NUM_TRAIN_DATA):\n",
    "        if A_3[0][x] == train_label[0][x]:\n",
    "            correct += 1\n",
    "        \n",
    "    train_accuracy[0][i] = i+1\n",
    "    train_accuracy[1][i] = correct/NUM_TRAIN_DATA\n",
    "    \n",
    "    # FOR CALCULATING VALIDATION LOSS   \n",
    "    z_1 = np.dot(w_1, val_data) + b_1\n",
    "    A_1 = sigmoid(z_1)\n",
    "    \n",
    "    z_2 = np.dot(w_2, A_1) + b_2\n",
    "    A_2 = sigmoid(z_2)\n",
    "    \n",
    "    z_3 = np.dot(w_3, A_2) + b_3\n",
    "    A_3 = sigmoid(z_3)\n",
    "    \n",
    "    J = (np.dot(val_label, (np.log(A_3)).T) + np.dot(1-val_label, (np.log(1-A_3)).T))\n",
    "    J = -np.sum(J)/NUM_VAL_DATA\n",
    "    val_loss[0][i] = i+1\n",
    "    val_loss[1][i] = J\n",
    "    \n",
    "    # FOR CALCULATING VALIDATION ACCURACY\n",
    "    for x in range(NUM_VAL_DATA):\n",
    "        if A_3[0][x] >= 0.5:\n",
    "            A_3[0][x] = 1\n",
    "        else:\n",
    "            A_3[0][x] = 0\n",
    "    \n",
    "    correct = 0\n",
    "    for x in range(NUM_VAL_DATA):\n",
    "        if A_3[0][x] == val_label[0][x]:\n",
    "            correct += 1\n",
    "        \n",
    "    val_accuracy[0][i] = i+1\n",
    "    val_accuracy[1][i] = correct/NUM_VAL_DATA\n",
    "    \n",
    "    if((i+1) % 1000 == 0):\n",
    "        print(\"Epoch \" + str(i+1) + \" Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN AND VALIDATION LOSS AT EVERY ITERATION\n",
    "fig, ax2 = plt.subplots(1,2,figsize=(20,6))\n",
    "ax2[0].set_title(\"Loss Value\")\n",
    "ax2[0].set_ylabel(\"Loss\", fontsize=\"12\")\n",
    "ax2[0].set_xlabel(\"iteration\", fontsize=\"12\")\n",
    "ax2[0].plot(train_loss[0], train_loss[1],'-r', label='Train Loss')\n",
    "ax2[0].plot(val_loss[0], val_loss[1], '-b', label='Validation Loss')\n",
    "ax2[0].legend(fontsize=\"12\")\n",
    "\n",
    "# PLOT TRAIN AND VALIDATION ACCURACY AT EVERY ITERATION\n",
    "ax2[1].set_title(\"Accuracy\")\n",
    "ax2[1].set_ylabel(\"Accuracy\", fontsize=\"12\")\n",
    "ax2[1].set_xlabel(\"iteration\", fontsize=\"12\")\n",
    "ax2[1].plot(train_accuracy[0], train_accuracy[1], '-y', label='Train Accuracy')\n",
    "ax2[1].plot(val_accuracy[0], val_accuracy[1], '-g', label='Validation Accuracy')\n",
    "ax2[1].legend(fontsize=\"12\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final accuracy and loss with training and validation datasets\n",
    "\n",
    "| Dataset | Loss | Accuracy |\n",
    "| --- | --- | --- |\n",
    "|Training|{ tl } | |\n",
    "|Validaiton | | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
